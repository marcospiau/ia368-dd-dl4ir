{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3r_2dnsAhY5K"
      ],
      "authorship_tag": "ABX9TyML9qnZQpjAQz9amOjGAz2L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcospiau/ia368-dd-dl4ir/blob/main/aula02/aula03_rerank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What's in here\n",
        "\n",
        "runs using:\n",
        "- pyserini BM25\n",
        "- our finetuned reranker: https://huggingface.co/marcospiau/MiniLM-L6-H384-uncased-msmarco-tiny-finetune\n",
        "- a good model cross_encoder: https://huggingface.co/cross-encoder/ms-marco-TinyBERT-L-2"
      ],
      "metadata": {
        "id": "7oKOns8yWR7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers toolz datasets ftfy neptune-client polars sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEbHsV9eWnn-",
        "outputId": "d0fe990a-7085-4900-fd2c-85c12690c415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 KB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.7/134.7 KB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 KB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.8/136.8 KB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "3r_2dnsAhY5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import toolz\n",
        "import transformers\n",
        "import torch\n",
        "import datasets\n",
        "import pandas as pd\n",
        "import toolz\n",
        "import fileinput\n",
        "import os\n",
        "import gc\n",
        "import itertools\n",
        "import functools\n",
        "import more_itertools\n",
        "import random\n",
        "from collections import Counter\n",
        "import ftfy\n",
        "import multiprocessing as mp\n",
        "import polars as pl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from tqdm import tqdm\n",
        "import pyarrow as pa\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "5qWXIYWzhaLe"
      },
      "execution_count": 362,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reranker finetuning\n",
        "\n",
        "Already done on finetune notebook."
      ],
      "metadata": {
        "id": "Fdz5rsGprXMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reranking"
      ],
      "metadata": {
        "id": "8mvkQ7ikWBz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup\n",
        "\n",
        "This notebook supposes that the following requirements are ready:\n",
        "- MSMARCO data is available locally\n",
        "- `anserini`, `anserini-tools` and `pyserini` are installed"
      ],
      "metadata": {
        "id": "YnRluxU7WEyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading queries with associated relevance judgements\n",
        "\n",
        "We can only evalute queries with associated relevant documents, so we will remove queries with no relevance judgments.\n",
        "\n",
        "These queries were generated during last class and we will use it "
      ],
      "metadata": {
        "id": "Im5or6UKedj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "ls -lht collections/msmarco-passage/topics.dl20.small.tsv\n",
        "head collections/msmarco-passage/topics.dl20.small.tsv\n",
        "wc -l collections/msmarco-passage/topics.dl20.small.tsv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va2cKH2diScE",
        "outputId": "10d1b057-f973-4c47-95e4-5c8cb3985dd8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-rw-r-- 1 marcospiau marcospiau 2.3K Mar  6 15:43 collections/msmarco-passage/topics.dl20.small.tsv\n",
            "1030303\twho is aziz hashim\n",
            "1037496\twho is rep scalise?\n",
            "1043135\twho killed nicholas ii of russia\n",
            "1051399\twho sings monk theme song\n",
            "1064670\twhy do hunters pattern their shotguns?\n",
            "1071750\twhy is pete rose banned from hall of fame\n",
            "1105792\tdefine: geon\n",
            "1106979\tdefine pareto chart in statistics\n",
            "1108651\twhat the best way to get clothes white\n",
            "1109707\twhat medium do radio waves travel through\n",
            "54 collections/msmarco-passage/topics.dl20.small.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_queries = (pl.read_csv('collections/msmarco-passage/topics.dl20.small.tsv',\n",
        "                       has_header=False, sep='\\t', \n",
        "                       new_columns=['qid', 'query']))\n",
        "len(df_queries), df_queries[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f66B9Kr9ib0C",
        "outputId": "e11acc39-75fb-4ec2-b077-947b9db10a68"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54,\n",
              " shape: (5, 2)\n",
              " ┌─────────┬─────────────────────────────────────┐\n",
              " │ qid     ┆ query                               │\n",
              " │ ---     ┆ ---                                 │\n",
              " │ i64     ┆ str                                 │\n",
              " ╞═════════╪═════════════════════════════════════╡\n",
              " │ 1030303 ┆ who is aziz hashim                  │\n",
              " │ 1037496 ┆ who is rep scalise?                 │\n",
              " │ 1043135 ┆ who killed nicholas ii of russia    │\n",
              " │ 1051399 ┆ who sings monk theme song           │\n",
              " │ 1064670 ┆ why do hunters pattern their sho... │\n",
              " └─────────┴─────────────────────────────────────┘)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries = df_queries.to_dicts()\n",
        "len(queries), queries[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3EqzdH_jxyT",
        "outputId": "cd8bbc0b-957e-498b-a83f-d7cd389cd613"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54,\n",
              " [{'qid': 1030303, 'query': 'who is aziz hashim'},\n",
              "  {'qid': 1037496, 'query': 'who is rep scalise?'},\n",
              "  {'qid': 1043135, 'query': 'who killed nicholas ii of russia'},\n",
              "  {'qid': 1051399, 'query': 'who sings monk theme song'},\n",
              "  {'qid': 1064670, 'query': 'why do hunters pattern their shotguns?'}])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BM25 run using pyserni\n",
        "\n",
        "We alreday have a run generated using Pyserini's BM25 from last class exercise and we will use it as a baseline result and also to use it as initial data for reranking. The command below was used to generate this run:\n",
        "\n",
        "```bash\n",
        "# Obs.: salvei em formato trec pra usar o script trec_eval\n",
        "mkdir -pv runs\n",
        "time python3 -m pyserini.search.lucene \\\n",
        "  --index indexes/lucene-index-msmarco-passage \\\n",
        "  --topics collections/msmarco-passage/topics.dl20.small.tsv \\\n",
        "  --output runs/run.dl20-passage.small.bm25default.txt \\\n",
        "  --output-format trec \\\n",
        "  --hits 1000 \\\n",
        "  --bm25 --k1 0.9 --b 0.4\n",
        "```"
      ],
      "metadata": {
        "id": "fNmEDKS3ik1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "wc runs/run.dl20-passage.small.bm25default.txt\n",
        "head runs/run.dl20-passage.small.bm25default.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNuUtDTFkKy8",
        "outputId": "72e45036-01d7-4e9d-9bb4-799ec98c03be"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  54000  324000 2175645 runs/run.dl20-passage.small.bm25default.txt\n",
            "23849 Q0 4348282 1 10.066300 Anserini\n",
            "23849 Q0 2674124 2 9.865500 Anserini\n",
            "23849 Q0 7119957 3 9.644200 Anserini\n",
            "23849 Q0 8133127 4 9.431700 Anserini\n",
            "23849 Q0 542113 5 9.385200 Anserini\n",
            "23849 Q0 2516458 6 9.338800 Anserini\n",
            "23849 Q0 4834498 7 9.251600 Anserini\n",
            "23849 Q0 436721 8 9.249500 Anserini\n",
            "23849 Q0 6667419 9 9.207700 Anserini\n",
            "23849 Q0 8246990 10 9.108900 Anserini\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics:"
      ],
      "metadata": {
        "id": "6L8IHhNVkfVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tools/eval/trec_eval.9.0.4/trec_eval -M 1000 -m ndcg_cut.10 tools/topics-and-qrels/qrels.dl20-passage.txt runs/run.dl20-passage.small.bm25default.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SypIrHdkgiQ",
        "outputId": "6c610dd1-fe97-4e4e-9995-b8c73005e59b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ndcg_cut_10           \tall\t0.4796\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting data for reranking"
      ],
      "metadata": {
        "id": "BB_WitQUks1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def raw_to_doc(raw):\n",
        "    decoded = json.loads(raw)\n",
        "    return {'id': decoded['id'],\n",
        "            'contents': ftfy.fix_text(decoded['contents'])}\n",
        "\n",
        "def get_doc(index_reader, docid: str):\n",
        "    docid = str(docid)\n",
        "    raw = index_reader.doc(docid).raw()\n",
        "    doc = raw_to_doc(raw)\n",
        "    assert doc['id'] == docid\n",
        "    return doc['contents']\n",
        "\n",
        "def load_run_polars(path):\n",
        "    return pl.read_csv(path, sep=' ', has_header=False, new_columns=[\n",
        "        'qid', 'q0', 'docid', 'rank', 'score', 'run_id'])\n",
        "\n",
        "def add_raw_docs_to_run_polars(df_run, index_reader):\n",
        "    get_doc_partial = functools.partial(get_doc, index_reader)\n",
        "    # retrieve distinct docids from index\n",
        "    doc_contents = (\n",
        "        df_run.select(pl.col('docid').unique())\n",
        "        .with_columns(\n",
        "            pl.col('docid').apply(get_doc_partial).alias('document'))\n",
        "    )\n",
        "    return (\n",
        "        df_run.select(pl.exclude('document'))\n",
        "        .join(doc_contents, on='docid', how='left'))\n",
        "\n",
        "def add_raw_batch_docs_to_run_polars(df_run, searcher, threads=32):\n",
        "    docids = df_run.get_column('docid').unique().cast(pl.Utf8).to_list()\n",
        "    doc_map = toolz.valmap(\n",
        "        lambda doc: raw_to_doc(doc.raw())['contents'],\n",
        "        searcher.batch_doc(docids, threads=threads)\n",
        "    )\n",
        "    return df_run.with_columns(\n",
        "        pl.col('docid').cast(pl.Utf8).map_dict(doc_map).alias('document')\n",
        "    )\n",
        "\n",
        "def add_query_to_runs(df_run, df_queries):\n",
        "    return (\n",
        "        df_run.select(pl.exclude('query'))\n",
        "        .join(df_queries, on='qid', how='left'))"
      ],
      "metadata": {
        "id": "2ZoFCRBEm0Si"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_by_n_words(df, cols=['query', 'document']):\n",
        "    \"\"\"Sort dataframe by total count of words of columns `cols`\"\"\"\n",
        "    n_words_expr = (\n",
        "        pl.sum(pl.col(*cols).str.split(' ').arr.lengths()).alias('n_words'))\n",
        "    return df.sort(n_words_expr)"
      ],
      "metadata": {
        "id": "s7RBCYQmZhRf"
      },
      "execution_count": 305,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyserini.index.lucene import IndexReader\n",
        "from pyserini.search.lucene import LuceneSearcher\n",
        "\n",
        "# we need the index with raw docs, not the slim one\n",
        "index_reader = IndexReader.from_prebuilt_index('msmarco-v1-passage')\n",
        "searcher = LuceneSearcher.from_prebuilt_index('msmarco-v1-passage')"
      ],
      "metadata": {
        "id": "aX8uMwT2oo0r"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_reader.stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNLRyVRWtvYv",
        "outputId": "6f8f2976-1180-4b96-ef28-8c43677ca408"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'total_terms': 352316036,\n",
              " 'documents': 8841823,\n",
              " 'non_empty_documents': 8841823,\n",
              " 'unique_terms': 2660824}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_bm25_run = load_run_polars('runs/run.dl20-passage.small.bm25default.txt')\n",
        "df_bm25_run.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "OWsKz9i2qZDl",
        "outputId": "639a6bae-f835-46f4-a9b5-3daac2cf9768"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (5, 6)\n",
              "┌───────┬─────┬─────────┬──────┬─────────┬──────────┐\n",
              "│ qid   ┆ q0  ┆ docid   ┆ rank ┆ score   ┆ run_id   │\n",
              "│ ---   ┆ --- ┆ ---     ┆ ---  ┆ ---     ┆ ---      │\n",
              "│ i64   ┆ str ┆ i64     ┆ i64  ┆ f64     ┆ str      │\n",
              "╞═══════╪═════╪═════════╪══════╪═════════╪══════════╡\n",
              "│ 23849 ┆ Q0  ┆ 4348282 ┆ 1    ┆ 10.0663 ┆ Anserini │\n",
              "│ 23849 ┆ Q0  ┆ 2674124 ┆ 2    ┆ 9.8655  ┆ Anserini │\n",
              "│ 23849 ┆ Q0  ┆ 7119957 ┆ 3    ┆ 9.6442  ┆ Anserini │\n",
              "│ 23849 ┆ Q0  ┆ 8133127 ┆ 4    ┆ 9.4317  ┆ Anserini │\n",
              "│ 23849 ┆ Q0  ┆ 542113  ┆ 5    ┆ 9.3852  ┆ Anserini │\n",
              "└───────┴─────┴─────────┴──────┴─────────┴──────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr > th,\n",
              ".dataframe > tbody > tr > td {\n",
              "  text-align: right;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>qid</th><th>q0</th><th>docid</th><th>rank</th><th>score</th><th>run_id</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>23849</td><td>&quot;Q0&quot;</td><td>4348282</td><td>1</td><td>10.0663</td><td>&quot;Anserini&quot;</td></tr><tr><td>23849</td><td>&quot;Q0&quot;</td><td>2674124</td><td>2</td><td>9.8655</td><td>&quot;Anserini&quot;</td></tr><tr><td>23849</td><td>&quot;Q0&quot;</td><td>7119957</td><td>3</td><td>9.6442</td><td>&quot;Anserini&quot;</td></tr><tr><td>23849</td><td>&quot;Q0&quot;</td><td>8133127</td><td>4</td><td>9.4317</td><td>&quot;Anserini&quot;</td></tr><tr><td>23849</td><td>&quot;Q0&quot;</td><td>542113</td><td>5</td><td>9.3852</td><td>&quot;Anserini&quot;</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_bm25_run = df_bm25_run.pipe(add_query_to_runs, df_queries)\n",
        "df_bm25_run.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "FTX9C37J1maM",
        "outputId": "507b7508-fb7b-4532-b2c9-8712ec457536"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (5, 7)\n",
              "┌───────┬─────┬─────────┬──────┬─────────┬──────────┬─────────────────────────────────────┐\n",
              "│ qid   ┆ q0  ┆ docid   ┆ rank ┆ score   ┆ run_id   ┆ query                               │\n",
              "│ ---   ┆ --- ┆ ---     ┆ ---  ┆ ---     ┆ ---      ┆ ---                                 │\n",
              "│ i64   ┆ str ┆ i64     ┆ i64  ┆ f64     ┆ str      ┆ str                                 │\n",
              "╞═══════╪═════╪═════════╪══════╪═════════╪══════════╪═════════════════════════════════════╡\n",
              "│ 23849 ┆ Q0  ┆ 4348282 ┆ 1    ┆ 10.0663 ┆ Anserini ┆ are naturalization records publi... │\n",
              "│ 23849 ┆ Q0  ┆ 2674124 ┆ 2    ┆ 9.8655  ┆ Anserini ┆ are naturalization records publi... │\n",
              "│ 23849 ┆ Q0  ┆ 7119957 ┆ 3    ┆ 9.6442  ┆ Anserini ┆ are naturalization records publi... │\n",
              "│ 23849 ┆ Q0  ┆ 8133127 ┆ 4    ┆ 9.4317  ┆ Anserini ┆ are naturalization records publi... │\n",
              "│ 23849 ┆ Q0  ┆ 542113  ┆ 5    ┆ 9.3852  ┆ Anserini ┆ are naturalization records publi... │\n",
              "└───────┴─────┴─────────┴──────┴─────────┴──────────┴─────────────────────────────────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr > th,\n",
              ".dataframe > tbody > tr > td {\n",
              "  text-align: right;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>qid</th><th>q0</th><th>docid</th><th>rank</th><th>score</th><th>run_id</th><th>query</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>23849</td><td>&quot;Q0&quot;</td><td>4348282</td><td>1</td><td>10.0663</td><td>&quot;Anserini&quot;</td><td>&quot;are naturaliza...</td></tr><tr><td>23849</td><td>&quot;Q0&quot;</td><td>2674124</td><td>2</td><td>9.8655</td><td>&quot;Anserini&quot;</td><td>&quot;are naturaliza...</td></tr><tr><td>23849</td><td>&quot;Q0&quot;</td><td>7119957</td><td>3</td><td>9.6442</td><td>&quot;Anserini&quot;</td><td>&quot;are naturaliza...</td></tr><tr><td>23849</td><td>&quot;Q0&quot;</td><td>8133127</td><td>4</td><td>9.4317</td><td>&quot;Anserini&quot;</td><td>&quot;are naturaliza...</td></tr><tr><td>23849</td><td>&quot;Q0&quot;</td><td>542113</td><td>5</td><td>9.3852</td><td>&quot;Anserini&quot;</td><td>&quot;are naturaliza...</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 by 1\n",
        "# df_bm25_run = df_bm25_run.pipe(add_raw_docs_to_run_polars, index_reader)\n",
        "df_bm25_run.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "cI9IPoXFnjr3",
        "outputId": "02ae90a1-8922-4798-bc8d-93c0710d2270"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (5, 7)\n",
              "┌───────┬─────┬─────────┬──────┬─────────┬──────────┬─────────────────────────────────────┐\n",
              "│ qid   ┆ q0  ┆ docid   ┆ rank ┆ score   ┆ run_id   ┆ query                               │\n",
              "│ ---   ┆ --- ┆ ---     ┆ ---  ┆ ---     ┆ ---      ┆ ---                                 │\n",
              "│ i64   ┆ str ┆ i64     ┆ i64  ┆ f64     ┆ str      ┆ str                                 │\n",
              "╞═══════╪═════╪═════════╪══════╪═════════╪══════════╪═════════════════════════════════════╡\n",
              "│ 23849 ┆ Q0  ┆ 4348282 ┆ 1    ┆ 10.0663 ┆ Anserini ┆ are naturalization records publi... │\n",
              "│ 23849 ┆ Q0  ┆ 2674124 ┆ 2    ┆ 9.8655  ┆ Anserini ┆ are naturalization records publi... │\n",
              "│ 23849 ┆ Q0  ┆ 7119957 ┆ 3    ┆ 9.6442  ┆ Anserini ┆ are naturalization records publi... │\n",
              "│ 23849 ┆ Q0  ┆ 8133127 ┆ 4    ┆ 9.4317  ┆ Anserini ┆ are naturalization records publi... │\n",
              "│ 23849 ┆ Q0  ┆ 542113  ┆ 5    ┆ 9.3852  ┆ Anserini ┆ are naturalization records publi... │\n",
              "└───────┴─────┴─────────┴──────┴─────────┴──────────┴─────────────────────────────────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr > th,\n",
              ".dataframe > tbody > tr > td {\n",
              "  text-align: right;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>qid</th><th>q0</th><th>docid</th><th>rank</th><th>score</th><th>run_id</th><th>query</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>23849</td><td>&quot;Q0&quot;</td><td>4348282</td><td>1</td><td>10.0663</td><td>&quot;Anserini&quot;</td><td>&quot;are naturaliza...</td></tr><tr><td>23849</td><td>&quot;Q0&quot;</td><td>2674124</td><td>2</td><td>9.8655</td><td>&quot;Anserini&quot;</td><td>&quot;are naturaliza...</td></tr><tr><td>23849</td><td>&quot;Q0&quot;</td><td>7119957</td><td>3</td><td>9.6442</td><td>&quot;Anserini&quot;</td><td>&quot;are naturaliza...</td></tr><tr><td>23849</td><td>&quot;Q0&quot;</td><td>8133127</td><td>4</td><td>9.4317</td><td>&quot;Anserini&quot;</td><td>&quot;are naturaliza...</td></tr><tr><td>23849</td><td>&quot;Q0&quot;</td><td>542113</td><td>5</td><td>9.3852</td><td>&quot;Anserini&quot;</td><td>&quot;are naturaliza...</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multithreaded batch\n",
        "df_bm25_run = add_raw_batch_docs_to_run_polars(df_bm25_run, searcher)\n",
        "df_bm25_run.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "0lt0xYWgtEqV",
        "outputId": "c1de9982-a4df-4f66-8dea-d9f0fc71816a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (5, 8)\n",
              "┌───────┬─────┬─────────┬──────┬─────────┬──────────┬───────────────────────┬──────────────────────┐\n",
              "│ qid   ┆ q0  ┆ docid   ┆ rank ┆ score   ┆ run_id   ┆ query                 ┆ document             │\n",
              "│ ---   ┆ --- ┆ ---     ┆ ---  ┆ ---     ┆ ---      ┆ ---                   ┆ ---                  │\n",
              "│ i64   ┆ str ┆ i64     ┆ i64  ┆ f64     ┆ str      ┆ str                   ┆ str                  │\n",
              "╞═══════╪═════╪═════════╪══════╪═════════╪══════════╪═══════════════════════╪══════════════════════╡\n",
              "│ 23849 ┆ Q0  ┆ 4348282 ┆ 1    ┆ 10.0663 ┆ Anserini ┆ are naturalization    ┆ Civil Records        │\n",
              "│       ┆     ┆         ┆      ┆         ┆          ┆ records publi...      ┆ Definition. Civil    │\n",
              "│       ┆     ┆         ┆      ┆         ┆          ┆                       ┆ ...                  │\n",
              "│ 23849 ┆ Q0  ┆ 2674124 ┆ 2    ┆ 9.8655  ┆ Anserini ┆ are naturalization    ┆ See our FAQ's to     │\n",
              "│       ┆     ┆         ┆      ┆         ┆          ┆ records publi...      ┆ learn how you c...   │\n",
              "│ 23849 ┆ Q0  ┆ 7119957 ┆ 3    ┆ 9.6442  ┆ Anserini ┆ are naturalization    ┆ Yes, in most cases   │\n",
              "│       ┆     ┆         ┆      ┆         ┆          ┆ records publi...      ┆ Public Record...     │\n",
              "│ 23849 ┆ Q0  ┆ 8133127 ┆ 4    ┆ 9.4317  ┆ Anserini ┆ are naturalization    ┆ Spokeo pulls data    │\n",
              "│       ┆     ┆         ┆      ┆         ┆          ┆ records publi...      ┆ and informatio...    │\n",
              "│ 23849 ┆ Q0  ┆ 542113  ┆ 5    ┆ 9.3852  ┆ Anserini ┆ are naturalization    ┆ Public Records –     │\n",
              "│       ┆     ┆         ┆      ┆         ┆          ┆ records publi...      ┆ Exemptions and ...   │\n",
              "└───────┴─────┴─────────┴──────┴─────────┴──────────┴───────────────────────┴──────────────────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr > th,\n",
              ".dataframe > tbody > tr > td {\n",
              "  text-align: right;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>qid</th><th>q0</th><th>docid</th><th>rank</th><th>score</th><th>run_id</th><th>query</th><th>document</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>23849</td><td>&quot;Q0&quot;</td><td>4348282</td><td>1</td><td>10.0663</td><td>&quot;Anserini&quot;</td><td>&quot;are naturaliza...</td><td>&quot;Civil Records ...</td></tr><tr><td>23849</td><td>&quot;Q0&quot;</td><td>2674124</td><td>2</td><td>9.8655</td><td>&quot;Anserini&quot;</td><td>&quot;are naturaliza...</td><td>&quot;See our FAQ&#x27;s ...</td></tr><tr><td>23849</td><td>&quot;Q0&quot;</td><td>7119957</td><td>3</td><td>9.6442</td><td>&quot;Anserini&quot;</td><td>&quot;are naturaliza...</td><td>&quot;Yes, in most c...</td></tr><tr><td>23849</td><td>&quot;Q0&quot;</td><td>8133127</td><td>4</td><td>9.4317</td><td>&quot;Anserini&quot;</td><td>&quot;are naturaliza...</td><td>&quot;Spokeo pulls d...</td></tr><tr><td>23849</td><td>&quot;Q0&quot;</td><td>542113</td><td>5</td><td>9.3852</td><td>&quot;Anserini&quot;</td><td>&quot;are naturaliza...</td><td>&quot;Public Records...</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reranking with our finetuned model"
      ],
      "metadata": {
        "id": "QZLGjHTdwIJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers.trainer_utils import RemoveColumnsCollator\n",
        "from transformers import DataCollatorWithPadding\n",
        "import inspect"
      ],
      "metadata": {
        "id": "zLJlGeog2tUe"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(ex, tokenizer, **tokenizer_kwargs):\n",
        "    \"\"\"Encode a pair of query and document using a tokenizer\"\"\"\n",
        "    return tokenizer(ex['query'], ex['document'], **tokenizer_kwargs)\n",
        "\n",
        "def generate_new_run(df_run, scores):\n",
        "    \"\"\"Generate new run from df_run and array of scores\"\"\"\n",
        "    df = (df_run.select('qid', 'q0', 'docid',\n",
        "                        pl.from_arrow(scores).alias('score'),\n",
        "                        pl.lit('DONT_CARE').alias('run_id')))\n",
        "    rank_expr = (pl.col('score').rank(method='ordinal', descending=True)\\\n",
        "                 .over('qid').alias('rank'))\n",
        "    df = df.with_columns(rank_expr).sort('qid', 'rank')\n",
        "    return df\n",
        "\n",
        "def write_df_run(df_run, path):\n",
        "    \"\"\"Serialize polars dataframe to trec format\"\"\"\n",
        "    cols_order = ['qid', 'q0', 'docid', 'rank', 'score', 'run_id']\n",
        "    to_write = df_run.select(cols_order).sort('qid', 'rank').rechunk()\n",
        "    return to_write.write_csv(path, has_header=False, sep=' ')\n",
        "\n",
        "class Reranker:\n",
        "    def __init__(self, model, tokenizer, max_length=200):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.encode = functools.partial(encode, tokenizer=tokenizer,\n",
        "                                        max_length=max_length,\n",
        "                                        padding=False, truncation=True,\n",
        "                                        return_length=True)\n",
        "        self.data_collator = DataCollatorWithPadding(\n",
        "            tokenizer=tokenizer, max_length=max_length,padding=True)\n",
        "        self.collate_fn = RemoveColumnsCollator(\n",
        "            data_collator=self.data_collator,\n",
        "            signature_columns=set(\n",
        "                inspect.signature(model.forward).parameters.keys()).union(\n",
        "                    {'label', 'label_ids'}))\n",
        "        self.partial_dataloader = functools.partial(\n",
        "            DataLoader, shuffle=False, collate_fn=self.collate_fn)\n",
        "        n_classes = model.classifier.out_features\n",
        "        if n_classes == 1:\n",
        "            self.is_cross_encoder = True\n",
        "        elif n_classes == 2:\n",
        "            self.is_cross_encoder = False\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f'n_classes should be 1 or 2, got {n_classes}')\n",
        "\n",
        "    \n",
        "    @torch.no_grad()\n",
        "    def __call__(self, df_runs, batch_size=128, sort_by_length=True):\n",
        "        \"\"\"Process a existing df_run into a new one, using reranked scores\"\"\"\n",
        "        # sort by n_words to reduce padding\n",
        "        if sort_by_length:\n",
        "            df_runs = sort_by_n_words(df_runs)\n",
        "        # load data into HuggingFaace dataset (zero-copy)\n",
        "        ds = datasets.arrow_dataset.Dataset(df_runs.to_arrow())\n",
        "        # encode and set format to torch (lazily)\n",
        "        ds = ds.with_transform(reranker.encode).to_iterable_dataset()\n",
        "        ds = ds.with_format('torch')\n",
        "        device = self.model.device\n",
        "        dataloader = self.partial_dataloader(ds, batch_size=batch_size)\n",
        "\n",
        "        all_scores = []\n",
        "        for batch in tqdm(dataloader, 'Scoring query-doc pairs',\n",
        "                          total=len(df_runs) // batch_size):\n",
        "            # send batch to same device as model\n",
        "            batch = toolz.valmap(lambda x: x.to(device), batch)\n",
        "            logits = self.model(**batch).logits\n",
        "            # OBS.: fiz isso pra funcionar apenas com o cross encoder que ia\n",
        "            # usar, não sei se fica certo pra todos\n",
        "            if self.is_cross_encoder:\n",
        "                scores = logits.ravel().sigmoid()\n",
        "            else:\n",
        "                # scores = torch.nn.functional.log_softmax(logits, dim=1)[:, 1].exp()\n",
        "                scores = logits.softmax(-1)[:, 1]\n",
        "            all_scores.append(pa.array(scores.numpy()))\n",
        "\n",
        "            \n",
        "        all_scores = pa.concat_arrays(all_scores)\n",
        "        new_run = generate_new_run(df_runs, all_scores)\n",
        "        return new_run"
      ],
      "metadata": {
        "id": "U2L3i1uS2bas"
      },
      "execution_count": 495,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = AutoModelForSequenceClassification.from_pretrained('marcospiau/MiniLM-L6-H384-uncased-msmarco-tiny-finetune')\n",
        "model.to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained('marcospiau/MiniLM-L6-H384-uncased-msmarco-tiny-finetune')\n",
        "reranker = Reranker(model, tokenizer)"
      ],
      "metadata": {
        "id": "-TCZDKHkcYfI"
      },
      "execution_count": 496,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_run_finetune = reranker(df_bm25_run, 128, True)\n",
        "print(df_run_finetune, df_run_finetune[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uOxa5KpcNto",
        "outputId": "d74223ff-2051-4a29-e2c9-427b13a92a73"
      },
      "execution_count": 497,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring query-doc pairs:   0%|                                                                                                                                                                                                                             | 0/421 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/home/marcospiau/disciplina/env_anserini/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2357: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "Scoring query-doc pairs: 422it [04:02,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (54000, 6)\n",
            "┌─────────┬─────┬─────────┬──────────┬───────────┬──────┐\n",
            "│ qid     ┆ q0  ┆ docid   ┆ score    ┆ run_id    ┆ rank │\n",
            "│ ---     ┆ --- ┆ ---     ┆ ---      ┆ ---       ┆ ---  │\n",
            "│ i64     ┆ str ┆ i64     ┆ f32      ┆ str       ┆ u32  │\n",
            "╞═════════╪═════╪═════════╪══════════╪═══════════╪══════╡\n",
            "│ 23849   ┆ Q0  ┆ 2647769 ┆ 0.999556 ┆ DONT_CARE ┆ 1    │\n",
            "│ 23849   ┆ Q0  ┆ 8010559 ┆ 0.999528 ┆ DONT_CARE ┆ 2    │\n",
            "│ 23849   ┆ Q0  ┆ 8010561 ┆ 0.999473 ┆ DONT_CARE ┆ 3    │\n",
            "│ 23849   ┆ Q0  ┆ 8010558 ┆ 0.999406 ┆ DONT_CARE ┆ 4    │\n",
            "│ ...     ┆ ... ┆ ...     ┆ ...      ┆ ...       ┆ ...  │\n",
            "│ 1136962 ┆ Q0  ┆ 80877   ┆ 0.000278 ┆ DONT_CARE ┆ 997  │\n",
            "│ 1136962 ┆ Q0  ┆ 8065423 ┆ 0.000277 ┆ DONT_CARE ┆ 998  │\n",
            "│ 1136962 ┆ Q0  ┆ 7101410 ┆ 0.000274 ┆ DONT_CARE ┆ 999  │\n",
            "│ 1136962 ┆ Q0  ┆ 1880431 ┆ 0.000272 ┆ DONT_CARE ┆ 1000 │\n",
            "└─────────┴─────┴─────────┴──────────┴───────────┴──────┘ shape: (5, 6)\n",
            "┌───────┬─────┬─────────┬──────────┬───────────┬──────┐\n",
            "│ qid   ┆ q0  ┆ docid   ┆ score    ┆ run_id    ┆ rank │\n",
            "│ ---   ┆ --- ┆ ---     ┆ ---      ┆ ---       ┆ ---  │\n",
            "│ i64   ┆ str ┆ i64     ┆ f32      ┆ str       ┆ u32  │\n",
            "╞═══════╪═════╪═════════╪══════════╪═══════════╪══════╡\n",
            "│ 23849 ┆ Q0  ┆ 2647769 ┆ 0.999556 ┆ DONT_CARE ┆ 1    │\n",
            "│ 23849 ┆ Q0  ┆ 8010559 ┆ 0.999528 ┆ DONT_CARE ┆ 2    │\n",
            "│ 23849 ┆ Q0  ┆ 8010561 ┆ 0.999473 ┆ DONT_CARE ┆ 3    │\n",
            "│ 23849 ┆ Q0  ┆ 8010558 ┆ 0.999406 ┆ DONT_CARE ┆ 4    │\n",
            "│ 23849 ┆ Q0  ┆ 188246  ┆ 0.998933 ┆ DONT_CARE ┆ 5    │\n",
            "└───────┴─────┴─────────┴──────────┴───────────┴──────┘\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FINETUNE_RUN_FILE = 'runs/run.dl20-passage.small.reranker.mini.lm.20.epochs.v1.txt'\n",
        "write_df_run(df_run_finetune, FINETUNE_RUN_FILE)\n",
        "!wc -l {FINETUNE_RUN_FILE}\n",
        "!head {FINETUNE_RUN_FILE}\n",
        "!tools/eval/trec_eval.9.0.4/trec_eval -M 1000 -m ndcg_cut.10 tools/topics-and-qrels/qrels.dl20-passage.txt runs/run.dl20-passage.small.reranker.mini.lm.20.epochs.v1.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-TWHgusHx7C",
        "outputId": "2a3e0448-879d-4f8f-ff54-8982ac2e091a"
      },
      "execution_count": 503,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "54000 runs/run.dl20-passage.small.reranker.mini.lm.20.epochs.v1.txt\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "23849 Q0 2647769 1 0.999556 DONT_CARE\n",
            "23849 Q0 8010559 2 0.9995277 DONT_CARE\n",
            "23849 Q0 8010561 3 0.9994733 DONT_CARE\n",
            "23849 Q0 8010558 4 0.99940634 DONT_CARE\n",
            "23849 Q0 188246 5 0.998933 DONT_CARE\n",
            "23849 Q0 1680203 6 0.99798274 DONT_CARE\n",
            "23849 Q0 653142 7 0.9978331 DONT_CARE\n",
            "23849 Q0 4806514 8 0.9974049 DONT_CARE\n",
            "23849 Q0 1622747 9 0.9962842 DONT_CARE\n",
            "23849 Q0 1449785 10 0.99620205 DONT_CARE\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ndcg_cut_10           \tall\t0.4146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del model, tokenizer, reranker\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAOvzECEh_AK",
        "outputId": "93d51e88-aafd-443b-af49-afec82699e75"
      },
      "execution_count": 499,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3160"
            ]
          },
          "metadata": {},
          "execution_count": 499
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reranking with a (probably) better finetune model - https://huggingface.co/cross-encoder/ms-marco-TinyBERT-L-2"
      ],
      "metadata": {
        "id": "2tDP7b5x8AiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_name = 'cross-encoder/ms-marco-TinyBERT-L-2'\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "model.to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "VjC3oUzrh8fL"
      },
      "execution_count": 500,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reranker = Reranker(model, tokenizer)\n",
        "df_run_cross_encoder = reranker(df_bm25_run, 128, True)\n",
        "print(df_run_cross_encoder.shape, df_run_cross_encoder, df_run_cross_encoder[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts6iKZIfiiLS",
        "outputId": "1bdb1772-a148-4123-f583-32599896227f"
      },
      "execution_count": 501,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scoring query-doc pairs:   0%|                                                                                                                                                                                                                             | 0/421 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/home/marcospiau/disciplina/env_anserini/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2357: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "Scoring query-doc pairs: 422it [00:43,  9.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54000, 6) shape: (54000, 6)\n",
            "┌─────────┬─────┬─────────┬──────────┬───────────┬──────┐\n",
            "│ qid     ┆ q0  ┆ docid   ┆ score    ┆ run_id    ┆ rank │\n",
            "│ ---     ┆ --- ┆ ---     ┆ ---      ┆ ---       ┆ ---  │\n",
            "│ i64     ┆ str ┆ i64     ┆ f32      ┆ str       ┆ u32  │\n",
            "╞═════════╪═════╪═════════╪══════════╪═══════════╪══════╡\n",
            "│ 23849   ┆ Q0  ┆ 8010561 ┆ 0.958647 ┆ DONT_CARE ┆ 1    │\n",
            "│ 23849   ┆ Q0  ┆ 2647769 ┆ 0.954198 ┆ DONT_CARE ┆ 2    │\n",
            "│ 23849   ┆ Q0  ┆ 4834498 ┆ 0.932085 ┆ DONT_CARE ┆ 3    │\n",
            "│ 23849   ┆ Q0  ┆ 8010558 ┆ 0.921999 ┆ DONT_CARE ┆ 4    │\n",
            "│ ...     ┆ ... ┆ ...     ┆ ...      ┆ ...       ┆ ...  │\n",
            "│ 1136962 ┆ Q0  ┆ 6058232 ┆ 0.000907 ┆ DONT_CARE ┆ 997  │\n",
            "│ 1136962 ┆ Q0  ┆ 4481766 ┆ 0.000905 ┆ DONT_CARE ┆ 998  │\n",
            "│ 1136962 ┆ Q0  ┆ 3422218 ┆ 0.000897 ┆ DONT_CARE ┆ 999  │\n",
            "│ 1136962 ┆ Q0  ┆ 8239770 ┆ 0.000871 ┆ DONT_CARE ┆ 1000 │\n",
            "└─────────┴─────┴─────────┴──────────┴───────────┴──────┘ shape: (5, 6)\n",
            "┌───────┬─────┬─────────┬──────────┬───────────┬──────┐\n",
            "│ qid   ┆ q0  ┆ docid   ┆ score    ┆ run_id    ┆ rank │\n",
            "│ ---   ┆ --- ┆ ---     ┆ ---      ┆ ---       ┆ ---  │\n",
            "│ i64   ┆ str ┆ i64     ┆ f32      ┆ str       ┆ u32  │\n",
            "╞═══════╪═════╪═════════╪══════════╪═══════════╪══════╡\n",
            "│ 23849 ┆ Q0  ┆ 8010561 ┆ 0.958647 ┆ DONT_CARE ┆ 1    │\n",
            "│ 23849 ┆ Q0  ┆ 2647769 ┆ 0.954198 ┆ DONT_CARE ┆ 2    │\n",
            "│ 23849 ┆ Q0  ┆ 4834498 ┆ 0.932085 ┆ DONT_CARE ┆ 3    │\n",
            "│ 23849 ┆ Q0  ┆ 8010558 ┆ 0.921999 ┆ DONT_CARE ┆ 4    │\n",
            "│ 23849 ┆ Q0  ┆ 5888570 ┆ 0.903538 ┆ DONT_CARE ┆ 5    │\n",
            "└───────┴─────┴─────────┴──────────┴───────────┴──────┘\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CROSS_ENCODER_RUN_FILE = 'runs/run.dl20-passage.small.reranker.cross.encoder.msmarco.tiny.bert.txt'\n",
        "write_df_run(df_run_cross_encoder, CROSS_ENCODER_RUN_FILE)\n",
        "!wc -l {CROSS_ENCODER_RUN_FILE}\n",
        "!head {CROSS_ENCODER_RUN_FILE}\n",
        "\n",
        "!tools/eval/trec_eval.9.0.4/trec_eval -M 1000 -m ndcg_cut.10 tools/topics-and-qrels/qrels.dl20-passage.txt {CROSS_ENCODER_RUN_FILE}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba07SdBkofIp",
        "outputId": "e3e5e398-8586-4857-e86b-61ccbe823033"
      },
      "execution_count": 502,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "54000 runs/run.dl20-passage.small.reranker.cross.encoder.msmarco.tiny.bert.txt\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "23849 Q0 8010561 1 0.95864666 DONT_CARE\n",
            "23849 Q0 2647769 2 0.9541975 DONT_CARE\n",
            "23849 Q0 4834498 3 0.93208456 DONT_CARE\n",
            "23849 Q0 8010558 4 0.92199904 DONT_CARE\n",
            "23849 Q0 5888570 5 0.90353805 DONT_CARE\n",
            "23849 Q0 4091551 6 0.7117987 DONT_CARE\n",
            "23849 Q0 2017213 7 0.69111776 DONT_CARE\n",
            "23849 Q0 8246990 8 0.66432697 DONT_CARE\n",
            "23849 Q0 8769995 9 0.6448785 DONT_CARE\n",
            "23849 Q0 886103 10 0.55778444 DONT_CARE\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ndcg_cut_10           \tall\t0.6235\n"
          ]
        }
      ]
    }
  ]
}